{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20220423KantaiBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVgC6KTwwaGRK+xWxOveEU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ftnext/practice-dl-nlp/blob/master/bert_exercise/20220423KantaiBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref: https://github.com/PacktPublishing/Transformers-for-Natural-Language-Processing/blob/main/Chapter03/KantaiBERT.ipynb"
      ],
      "metadata": {
        "id": "zWd6RZEwuuUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Fetch dataset"
      ],
      "metadata": {
        "id": "Iq1UMvkLMiAs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q30KExIY9rCm",
        "outputId": "e0631416-f39a-4d9c-b3a9-b7448fce6a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 10.7M  100 10.7M    0     0  20.4M      0 --:--:-- --:--:-- --:--:-- 20.4M\n"
          ]
        }
      ],
      "source": [
        "!curl --output kant.txt \\\n",
        "  https://raw.githubusercontent.com/PacktPublishing/Transformers-for-Natural-Language-Processing/main/Chapter03/kant.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh kant.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7Q5ekUL-Ipj",
        "outputId": "8e538b06-32e8-41d3-c33f-d9e55148e95d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 11M Apr 23 07:05 kant.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l kant.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go-R4V-I-RPw",
        "outputId": "b0006429-b102-486a-897d-df2c79cad85b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188287 kant.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep -n 'Gutenberg EBook' kant.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khX8Ex37-W3G",
        "outputId": "7bf2c6a4-bce4-43a0-8a23-82fabba64983"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2:The Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "20816:End of the Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "21180:The Project Gutenberg EBook of Fundamental Principles of the Metaphysic of Morals\n",
            "31383:The Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "52197:End of the Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "52561:The Project Gutenberg EBook of Fundamental Principles of the Metaphysic of Morals\n",
            "62764:The Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "83578:End of the Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "83942:The Project Gutenberg EBook of Fundamental Principles of the Metaphysic of Morals\n",
            "94145:The Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "114959:End of the Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "115323:The Project Gutenberg EBook of Fundamental Principles of the Metaphysic of Morals\n",
            "125525:The Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "146339:End of the Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "146703:The Project Gutenberg EBook of Fundamental Principles of the Metaphysic of Morals\n",
            "156906:The Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "177720:End of the Project Gutenberg EBook of The Critique of Pure Reason, by Immanuel Kant\n",
            "178084:The Project Gutenberg EBook of Fundamental Principles of the Metaphysic of Morals\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Install dependencies"
      ],
      "metadata": {
        "id": "T-5g9TH8Mu6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVnimVBL_Rsw",
        "outputId": "c149a4c2-3de1-44a5-b95d-f741d2870f35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.0\n",
            "Uninstalling tensorflow-2.8.0:\n",
            "  Successfully uninstalled tensorflow-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPUxicc-_rLI",
        "outputId": "57a0bbd5-09a8-46e8-c612-58af3284edfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 34.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep -E 'transformers|tokenizers'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UJeacZG_2Uo",
        "outputId": "e84997be-5efa-4b54-acd4-85af5eb63ec7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizers                    0.12.1\n",
            "transformers                  4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check GPU"
      ],
      "metadata": {
        "id": "9PF2fER-M1Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqeH9L3OWwVo",
        "outputId": "83903da0-ff10-454d-c04b-c66339bfa31b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Apr 23 07:06:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "nLYDe6VwWnpf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqDoTP4KWqL7",
        "outputId": "bd2c1697-49b6-4ac5-ed56-e8db213db804"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "JW6PwXa7M-kc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "GenqJde6_-lz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing"
      ],
      "metadata": {
        "id": "BTOWAQ1-NmB7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    pipeline,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    LineByLineTextDataset,\n",
        "    RobertaConfig,\n",
        "    RobertaTokenizer,\n",
        "    RobertaForMaskedLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")"
      ],
      "metadata": {
        "id": "z1Qyw3NbNi_X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer"
      ],
      "metadata": {
        "id": "3u6KYdTLN1GV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train tokenizer then save"
      ],
      "metadata": {
        "id": "kP5ypEqXM5I2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]  # == [\"kant.txt\"]\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer()"
      ],
      "metadata": {
        "id": "YUuweWHBIWLI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "special_tokens = [\"<s>\", \"<pad>\", \"</s>\", \"<unk>\",\"<mask>\"]\n",
        "\n",
        "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=special_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k30EXiXeIJmI",
        "outputId": "5d4866cf-0d06-4fd4-d8f7-7aa16b62b95a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.72 s, sys: 242 ms, total: 6.96 s\n",
            "Wall time: 3.65 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_dir = Path(\"KantaiBERT\")\n",
        "token_dir.mkdir(exist_ok=True)\n",
        "\n",
        "tokenizer.save_model(str(token_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3TYbG_vJVE4",
        "outputId": "feb32024-c49f-4e75-9270-5344d282b96f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['KantaiBERT/vocab.json', 'KantaiBERT/merges.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh KantaiBERT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfhfbHGTMc8_",
        "outputId": "74f7ff95-e480-45b2-e81e-aeec8de0ec25"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 496K\n",
            "-rw-r--r-- 1 root root 186K Apr 23 07:07 merges.txt\n",
            "-rw-r--r-- 1 root root 308K Apr 23 07:07 vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l KantaiBERT/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQPUm-3FM4R7",
        "outputId": "d7ce098f-20f6-48fe-d652-7f82c5af2601"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 19036 KantaiBERT/merges.txt\n",
            "     0 KantaiBERT/vocab.json\n",
            " 19036 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.get_vocab_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahYBHfLVM8ni",
        "outputId": "d79d80cd-3460-4337-d6db-c6e3e1aa0d06"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19296"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.get_vocab())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx_pua13NY32",
        "outputId": "dd41dd68-3a5b-419a-cc01-5aee0304e9e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19296"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load tokenizer (as huggingface/tokenizers)"
      ],
      "metadata": {
        "id": "B4ek342_NrZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    f\"{token_dir}/vocab.json\", f\"{token_dir}/merges.txt\"\n",
        ")"
      ],
      "metadata": {
        "id": "o6l_6oJNPgCR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.get_vocab_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evbjFdoCQGg5",
        "outputId": "932f35b9-2725-4974-8140-d49877a6629b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19296"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"The Critique of Pure Reason.\").tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-mElyNwQIUk",
        "outputId": "56b551e8-5ad7-44f3-b820-b8036a2e69ac"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'ĠCritique', 'Ġof', 'ĠPure', 'ĠReason', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),  # [SEP]\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")), # [CLS]\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "metadata": {
        "id": "7XJ55Xc5Vy3b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"The Critique of Pure Reason.\").tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbQnHsg2WULW",
        "outputId": "ab92c615-7400-494c-b5a3-f033a64304b7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'The', 'ĠCritique', 'Ġof', 'ĠPure', 'ĠReason', '.', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RoBERTa"
      ],
      "metadata": {
        "id": "Zibzq0bON5pt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config"
      ],
      "metadata": {
        "id": "z6YehG6JN79S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "metadata": {
        "id": "CSghJRzovg9q"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "Qx4fhd9uN_Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(str(token_dir), max_length=512)"
      ],
      "metadata": {
        "id": "ur6uSoFHytga"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"The Critique of Pure Reason.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHwPtpnFy52d",
        "outputId": "67342d66-109d-4b42-8c83-b2a734c741cb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 803, 2245, 270, 1410, 1270, 18, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "cnpmjUG0OBbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaForMaskedLM(config)"
      ],
      "metadata": {
        "id": "KPVwuq6F7Rq5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.num_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJ34lE9-70-b",
        "outputId": "3b681596-9870-4996-9d43-04d1b98853f8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83504416"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset (for pre-training)"
      ],
      "metadata": {
        "id": "GoFG-b2YODVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "dataset = LineByLineTextDataset(\n",
        "    tokenizer=tokenizer, file_path=\"kant.txt\", block_size=128\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlDAAqemE6dk",
        "outputId": "0ad4de7b-9e60-4c93-bdc7-e08d3d73809f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:125: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 36.3 s, sys: 1.11 s, total: 37.4 s\n",
            "Wall time: 37.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRqv_ofiFK2W",
        "outputId": "83c8df1a-a523-4da2-fd6c-af75b4981a67"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170964"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYgyTnoWFm7O",
        "outputId": "3e7c6730-c15d-4915-df08-b32a0392d42a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([   0,  803, 1123, 1156, 8937,  270,  487, 2245,  270, 1410, 1270,   16,\n",
              "          379, 4555, 4032,    2])}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data collator"
      ],
      "metadata": {
        "id": "YAMjpk6GOHHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "metadata": {
        "id": "qop18WlZGlOw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "HUNzxyfoOKnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=str(token_dir),\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")"
      ],
      "metadata": {
        "id": "Fs-9vYUPOMHc"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "OBdnhr-ZOrXy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "M_knalWBO6gg",
        "outputId": "e0d4e6a4-d0d9-405c-b133-a3b2f0d2c0bc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 170964\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2672\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2672' max='2672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2672/2672 18:59, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>6.592300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.759700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>5.291600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.023300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>4.869600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 18min 57s, sys: 5.64 s, total: 19min 3s\n",
            "Wall time: 19min\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2672, training_loss=5.463243130438342, metrics={'train_runtime': 1140.1473, 'train_samples_per_second': 149.949, 'train_steps_per_second': 2.344, 'total_flos': 873620128952064.0, 'train_loss': 5.463243130438342, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(str(token_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydwDNOkmPGJH",
        "outputId": "0ac2dad4-6c69-48a0-b581-893bf2af85d5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to KantaiBERT\n",
            "Configuration saved in KantaiBERT/config.json\n",
            "Model weights saved in KantaiBERT/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fill-mask task"
      ],
      "metadata": {
        "id": "mTHKi22fPDUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask = pipeline(\n",
        "    \"fill-mask\",\n",
        "    model=str(token_dir),\n",
        "    tokenizer=str(token_dir)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlHctUCAPE26",
        "outputId": "98d749d1-34a7-4380-918d-3ddb514b7a4d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file KantaiBERT/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"KantaiBERT\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file KantaiBERT/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"KantaiBERT\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading weights file KantaiBERT/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
            "\n",
            "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at KantaiBERT.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file KantaiBERT/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"KantaiBERT\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "Didn't find file KantaiBERT/tokenizer.json. We won't load it.\n",
            "Didn't find file KantaiBERT/added_tokens.json. We won't load it.\n",
            "Didn't find file KantaiBERT/special_tokens_map.json. We won't load it.\n",
            "Didn't find file KantaiBERT/tokenizer_config.json. We won't load it.\n",
            "loading file KantaiBERT/vocab.json\n",
            "loading file KantaiBERT/merges.txt\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading file None\n",
            "loading configuration file KantaiBERT/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"KantaiBERT\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n",
            "loading configuration file KantaiBERT/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"KantaiBERT\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 52000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask(\"Human thinking involves<mask>.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS4bQRzhWZBy",
        "outputId": "3ecf12c7-f07c-411f-8682-bac9a481aab0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.023670444265007973,\n",
              "  'sequence': 'Human thinking involves reason.',\n",
              "  'token': 393,\n",
              "  'token_str': ' reason'},\n",
              " {'score': 0.015469097532331944,\n",
              "  'sequence': 'Human thinking involves it.',\n",
              "  'token': 306,\n",
              "  'token_str': ' it'},\n",
              " {'score': 0.012228215113282204,\n",
              "  'sequence': 'Human thinking involves conceptions.',\n",
              "  'token': 605,\n",
              "  'token_str': ' conceptions'},\n",
              " {'score': 0.011805330403149128,\n",
              "  'sequence': 'Human thinking involves experience.',\n",
              "  'token': 531,\n",
              "  'token_str': ' experience'},\n",
              " {'score': 0.009144469164311886,\n",
              "  'sequence': 'Human thinking involves them.',\n",
              "  'token': 508,\n",
              "  'token_str': ' them'}]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fill_mask(\"Human thinking involves <mask>.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJhwuaboW8VY",
        "outputId": "a660b9cb-b9a8-49ef-a497-ff6b26d97b9a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.023670444265007973,\n",
              "  'sequence': 'Human thinking involves reason.',\n",
              "  'token': 393,\n",
              "  'token_str': ' reason'},\n",
              " {'score': 0.015469097532331944,\n",
              "  'sequence': 'Human thinking involves it.',\n",
              "  'token': 306,\n",
              "  'token_str': ' it'},\n",
              " {'score': 0.012228215113282204,\n",
              "  'sequence': 'Human thinking involves conceptions.',\n",
              "  'token': 605,\n",
              "  'token_str': ' conceptions'},\n",
              " {'score': 0.011805330403149128,\n",
              "  'sequence': 'Human thinking involves experience.',\n",
              "  'token': 531,\n",
              "  'token_str': ' experience'},\n",
              " {'score': 0.009144469164311886,\n",
              "  'sequence': 'Human thinking involves them.',\n",
              "  'token': 508,\n",
              "  'token_str': ' them'}]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export artifacts"
      ],
      "metadata": {
        "id": "u2F6yRBYY3-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh KantaiBERT/*.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br0QSKxKYCB1",
        "outputId": "1824c15d-3355-4107-f4ff-e83826831b05"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root  636 Apr 23 07:34 KantaiBERT/config.json\n",
            "-rw-r--r-- 1 root root 186K Apr 23 07:07 KantaiBERT/merges.txt\n",
            "-rw-r--r-- 1 root root 319M Apr 23 07:34 KantaiBERT/pytorch_model.bin\n",
            "-rw-r--r-- 1 root root 3.0K Apr 23 07:34 KantaiBERT/training_args.bin\n",
            "-rw-r--r-- 1 root root 308K Apr 23 07:07 KantaiBERT/vocab.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp KantaiBERT/*.* drive/MyDrive/nlp/20220423/KantaiBERT/"
      ],
      "metadata": {
        "id": "Kbb2NrvWYO8W"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}